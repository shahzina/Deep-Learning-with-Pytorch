{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part- 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(x):\n",
    "    return 1/(1+torch.exp(-x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(7) #generates data\n",
    "\n",
    "#generates 5 random vars, size is 1 row and 5 columns\n",
    "features = torch.randn((1,5))\n",
    "\n",
    "#generate weights with same shape as features\n",
    "weights = torch.randn_like(features)\n",
    "\n",
    "#define a bias term\n",
    "bias = torch.randn((1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1595]])\n"
     ]
    }
   ],
   "source": [
    "#First, calculate output using weights and bias tensors\n",
    "\n",
    "y = activation((features*weights).sum() + bias)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1595]])\n"
     ]
    }
   ],
   "source": [
    "# Second, calculate output of network using matrix multiplication\n",
    "\n",
    "y = activation(torch.mm(features, weights.view(5,1)) + bias)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding more layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate more data\n",
    "torch.manual_seed(7)\n",
    "\n",
    "#features are 3 random normal variables\n",
    "features = torch.randn((1,3))\n",
    "\n",
    "#define the size of each layer in the network\n",
    "n_input = features.shape[1] #must match number of input features\n",
    "n_hidden = 2\n",
    "n_output = 1\n",
    "\n",
    "#weights for input to hidden layer\n",
    "w1 = torch.randn(n_input,n_hidden)\n",
    "\n",
    "#weights for hidden to output layer\n",
    "w2 = torch.randn(n_hidden, n_output)\n",
    "\n",
    "#bias terms for both layers\n",
    "b1 = torch.randn((1, n_hidden))\n",
    "b2 = torch.randn((1, n_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3171]])\n"
     ]
    }
   ],
   "source": [
    "h = activation(torch.mm(features, w1) + b1)\n",
    "output = activation(torch.mm(h, w2) + b2)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part- 2 Neural Networks with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import more packages\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import helper\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "#data normalization using transform\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,),(0.5,)),\n",
    "                               ])\n",
    "\n",
    "#download and load training data aka MNIST dataset here. \n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', \n",
    "                         download = True,\n",
    "                         train = True, \n",
    "                         transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset,\n",
    "                                         batch_size=64, #64 images in each iteration\n",
    "                                         shuffle =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader) #iterate thru dataset \n",
    "images, labels = dataiter.next() #get the image and associated label in each iteration\n",
    "\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1291b80b8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAWJQAAFiUBSVIk8AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAGa5JREFUeJzt3X2sbXdd5/HP115Dh0ZKh6iNcUyBoa0R206LUttQ+hAZ0FhbaGdIfGhIMejoYBEmThScizoJf0ykFMaiojYpyVRTAsaxAhNa2kJxDEXoEIFSy6WDtkLptAUKaOE3f+x15Ho45z6cs+9Z537365XsrLPX2mvv310s+j5rn7XXrjFGAICevmXuAQAAR47QA0BjQg8AjQk9ADQm9ADQmNADQGNCDwCNCT0ANCb0ANCY0ANAY0IPAI0JPQA0JvQA0JjQA0BjQg8AjQk9ADS2Z+4BHAlV9akkT0qyb+ahAMBWnZTk0THGU7fzJC1Dn0Xk/+V0A4CVNetb91X13VX1B1X1d1X11araV1VXV9UJ23zqfcsYHwDMbN92n2C2I/qqenqSO5J8R5I/SfLxJD+Y5BeTPL+qzh1jfH6u8QFAB3Me0f92FpF/+RjjkjHGfx5jXJjk9UlOSfJfZxwbALRQY4ydf9HF0fw9Wbwl8fQxxtf3W/ZtSe5PUkm+Y4zxpS08/51JzlzOaAFgNh8aY5y1nSeY64j+gmn67v0jnyRjjC8keX+SJyY5e6cHBgCdzPU3+lOm6d2bLP9kkuclOTnJezZ7kunIfSOnbn1oANDHXEf0x0/TRzZZvjb/yTswFgBo66j+HP1mf7fwN3oAWJjriH7tiP34TZavzX94B8YCAG3NFfpPTNOTN1n+jGm62d/wAYBDMFfob5mmz6uqfzaG6eN15yZ5LMlf7PTAAKCTWUI/xvibJO/O4oL9P79u8WuTHJfk+q18hh4A+IY5T8b7D1lcAveaqrooyceSPDuLz9jfneRXZxwbALQw2yVwp6P6ZyW5LovAvzLJ05O8IcnZrnMPANs368frxhj/N8lL5hwDAHQ269fUAgBHltADQGNCDwCNCT0ANCb0ANCY0ANAY0IPAI0JPQA0JvQA0JjQA0BjQg8AjQk9ADQm9ADQmNADQGNCDwCNCT0ANCb0ANCY0ANAY0IPAI0JPQA0JvQA0JjQA0BjQg8AjQk9ADQm9ADQmNADQGNCDwCNCT0ANCb0ANCY0ANAY0IPAI0JPQA0JvQA0JjQA0BjQg8AjQk9ADQm9ADQmNADQGNCDwCNCT0ANCb0ANCY0ANAY0IPAI0JPQA0JvQA0JjQA0Bje+YeADCfa665Zsvr/sRP/MS2XvuZz3zmtta///77t7U+rApH9ADQmNADQGNCDwCNCT0ANCb0ANCY0ANAY0IPAI0JPQA0JvQA0JjQA0BjQg8AjQk9ADQm9ADQmNADQGNCDwCN+T56WGHnnnvultc94YQTtvXaJ5544rbW9330cGhmO6Kvqn1VNTa5PTDXuACgk7mP6B9JcvUG87+40wMBgI7mDv3DY4y9M48BANpyMh4ANDb3Ef0Tquonk3xPki8luSvJbWOMr807LADoYe7Qn5jk+nXzPlVVLxlj3Hqwlavqzk0WnbrtkQFAA3O+df+HSS7KIvbHJfn+JL+T5KQkf15Vp883NADoYbYj+jHGa9fN+miSn62qLyZ5ZZK9SS49yHOctdH86Uj/zCUMEwCOarvxZLw3T9PzZh0FADSwG0P/uWl63KyjAIAGdmPoz56m9846CgBoYJbQV9X3VtU3HbFX1UlJ3jTdfetOjgkAOprrZLx/n+SVVXVbkk8n+UKSpyf50STHJrkpyX+baWwA0MZcob8lySlJ/k2Sc7P4e/zDSd6Xxefqrx9jjJnGBgBtzBL66WI4B70gDgCwPbvxZDwAYEmEHgAaE3oAaEzoAaAxoQeAxoQeABoTegBoTOgBoDGhB4DGhB4AGhN6AGhM6AGgMaEHgMaEHgAaE3oAaEzoAaAxoQeAxoQeABoTegBoTOgBoDGhB4DGhB4AGhN6AGhM6AGgMaEHgMaEHgAaE3oAaEzoAaAxoQeAxoQeABrbM/cAgPlce+21W173d3/3d5c4EuBIcUQPAI0JPQA0JvQA0JjQA0BjQg8AjQk9ADQm9ADQmNADQGNCDwCNCT0ANCb0ANCY0ANAY0IPAI0JPQA0JvQA0Jjvo4cV9sADD8z22s95znO2tf5f/dVfLWkk0JsjegBoTOgBoDGhB4DGhB4AGhN6AGhM6AGgMaEHgMaEHgAaE3oAaEzoAaAxoQeAxoQeABoTegBoTOgBoDFfUwvM4uKLL97W+tdcc82SRgK9LeWIvqouq6o3VtXtVfVoVY2qeutB1jmnqm6qqoeq6stVdVdVXVVVxyxjTADA8o7oX53k9CRfTPKZJKce6MFV9eNJ3pbkK0n+KMlDSX4syeuTnJvk8iWNCwBW2rL+Rv+KJCcneVKSnzvQA6vqSUl+L8nXkpw/xrhyjPGfkpyR5ANJLquqFy9pXACw0pYS+jHGLWOMT44xxiE8/LIk357khjHGB/d7jq9k8c5AcpBfFgCAQzPHWfcXTtN3brDstiSPJTmnqp6wc0MCgJ7mCP0p0/Tu9QvGGI8n+VQW5w48bScHBQAdzfHxuuOn6SObLF+b/+SDPVFV3bnJogOeDAgAq8IFcwCgsTmO6NeO2I/fZPna/IcP9kRjjLM2mj8d6Z95+EMDgF7mOKL/xDQ9ef2CqtqT5KlJHk9y704OCgA6miP0N0/T52+w7LwkT0xyxxjjqzs3JADoaY7Q35jkwSQvrqpnrc2sqmOT/OZ099oZxgUA7Szlb/RVdUmSS6a7J07TH6qq66afHxxjvCpJxhiPVtXPZBH891bVDVlcAvfiLD56d2MWl8UFALZpWSfjnZHkinXznpZvfBb+00letbZgjPGOqnpukl9N8qIkxya5J8kvJbnmEK+wBwAcxFJCP8bYm2TvYa7z/iQ/sozXBwA25nP0ANCY0ANAY0IPAI0JPQA0JvQA0JjQA0BjQg8AjQk9ADQm9ADQmNADQGNCDwCNCT0ANCb0ANCY0ANAY0IPAI0t5fvogaPTpZdeOvcQgCPMET0ANCb0ANCY0ANAY0IPAI0JPQA0JvQA0JjQA0BjQg8AjQk9ADQm9ADQmNADQGNCDwCNCT0ANCb0ANCY0ANAY76PHlbYGWecMfcQgCPMET0ANCb0ANCY0ANAY0IPAI0JPQA0JvQA0JjQA0BjQg8AjQk9ADQm9ADQmNADQGNCDwCNCT0ANCb0ANCY0ANAY0IPAI0JPQA0JvQA0JjQA0BjQg8AjQk9ADQm9ADQmNADQGNCDwCNCT0ANCb0ANCY0ANAY0IPAI0JPQA0JvQA0NieuQcArKarr7567iHASljKEX1VXVZVb6yq26vq0aoaVfXWTR570rR8s9sNyxgTALC8I/pXJzk9yReTfCbJqYewzkeSvGOD+R9d0pgAYOUtK/SvyCLw9yR5bpJbDmGdD48x9i7p9QGADSwl9GOMfwp7VS3jKQGAJZjzZLzvqqqXJXlKks8n+cAY464ZxwMA7cwZ+h+ebv+kqt6b5Ioxxn2H8gRVdecmiw7lHAEAaG+Oz9E/luQ3kpyV5ITptvZ3/fOTvKeqjpthXADQzo4f0Y8xPpvk19bNvq2qnpfkfUmeneSlSd5wCM911kbzpyP9M7c5VAA46u2aK+ONMR5P8pbp7nlzjgUAutg1oZ98bpp66x4AlmC3hf7saXrvrKMAgCZ2PPRVdWZVfdPrVtVFWVx4J0k2vHwuAHB4lnIyXlVdkuSS6e6J0/SHquq66ecHxxivmn7+rSTPqKo7sriaXpKcluTC6efXjDHuWMa4AGDVLeus+zOSXLFu3tOmW5J8Osla6K9PcmmSH0jygiTfmuTvk/xxkjeNMW5f0pgAYOUt6xK4e5PsPcTH/n6S31/G6wIAB+b76OEodvrpp29r/dNOO21JIzl8f/u3fzvba8Mq2W1n3QMASyT0ANCY0ANAY0IPAI0JPQA0JvQA0JjQA0BjQg8AjQk9ADQm9ADQmNADQGNCDwCNCT0ANCb0ANCYr6mFo9iePdv7v/AxxxyzpJEAu5UjegBoTOgBoDGhB4DGhB4AGhN6AGhM6AGgMaEHgMaEHgAaE3oAaEzoAaAxoQeAxoQeABoTegBoTOgBoDGhB4DGfB89rLCq2vK6Y4wljgQ4UhzRA0BjQg8AjQk9ADQm9ADQmNADQGNCDwCNCT0ANCb0ANCY0ANAY0IPAI0JPQA0JvQA0JjQA0BjQg8AjfmaWlhhvmoW+nNEDwCNCT0ANCb0ANCY0ANAY0IPAI0JPQA0JvQA0JjQA0BjQg8AjQk9ADQm9ADQmNADQGNCDwCNCT0ANCb0ANCY76OHo9iVV1459xCAXW7bR/RV9ZSqemlVvb2q7qmqL1fVI1X1vqq6sqo2fI2qOqeqbqqqh6Z17qqqq6rqmO2OCQBYWMYR/eVJrk1yf5JbktyX5DuTvDDJW5K8oKouH2OMtRWq6seTvC3JV5L8UZKHkvxYktcnOXd6TgBgm5YR+ruTXJzkz8YYX1+bWVW/kuQvk7woi+i/bZr/pCS/l+RrSc4fY3xwmv+aJDcnuayqXjzGuGEJYwOAlbbtt+7HGDePMf50/8hP8x9I8ubp7vn7LbosybcnuWEt8tPjv5Lk1dPdn9vuuACAI3/W/T9O08f3m3fhNH3nBo+/LcljSc6pqiccyYEBwCo4YmfdV9WeJD893d0/6qdM07vXrzPGeLyqPpXk+5I8LcnHDvIad26y6NTDGy0A9HQkj+hfl+SZSW4aY7xrv/nHT9NHNllvbf6Tj9TAAGBVHJEj+qp6eZJXJvl4kp86Eq+RJGOMszZ5/TuTnHmkXhcAjhZLP6Kvql9I8oYkf53kgjHGQ+sesnbEfnw2tjb/4WWPDQBWzVJDX1VXJXljko9mEfkHNnjYJ6bpyRusvyfJU7M4ee/eZY4NAFbR0kJfVb+cxQVvPpxF5D+7yUNvnqbP32DZeUmemOSOMcZXlzU2AFhVSwn9dLGb1yW5M8lFY4wHD/DwG5M8mOTFVfWs/Z7j2CS/Od29dhnjAoBVt+2T8arqiiS/nsWV7m5P8vKqWv+wfWOM65JkjPFoVf1MFsF/b1XdkMUlcC/O4qN3N2ZxWVwAYJuWcdb9U6fpMUmu2uQxtya5bu3OGOMdVfXcJL+axSVyj01yT5JfSnLN/tfFBwC2btuhH2PsTbJ3C+u9P8mPbPf1YZWdcsopB38QsNKO9CVwAYAZCT0ANCb0ANCY0ANAY0IPAI0JPQA0JvQA0JjQA0BjQg8AjQk9ADQm9ADQmNADQGNCDwCNCT0ANCb0ANCY0ANAY0IPAI0JPQA0JvQA0JjQA0BjQg8AjQk9ADQm9ADQmNADQGNCDwCNCT0ANCb0ANCY0ANAY0IPAI0JPQA0tmfuAQBbd+utt25r/QsuuGDL6951113beu3trg8cGkf0ANCY0ANAY0IPAI0JPQA0JvQA0JjQA0BjQg8AjQk9ADQm9ADQmNADQGNCDwCNCT0ANCb0ANCY0ANAY0IPAI3VGGPuMSxdVd2Z5My5xwEA2/ShMcZZ23kCR/QA0JjQA0BjQg8AjQk9ADQm9ADQmNADQGNCDwCNCT0ANCb0ANCY0ANAY0IPAI0JPQA0JvQA0JjQA0BjQg8AjW079FX1lKp6aVW9varuqaovV9UjVfW+qrqyqr5l3eNPqqpxgNsN2x0TALCwZwnPcXmSa5Pcn+SWJPcl+c4kL0zyliQvqKrLxxhj3XofSfKODZ7vo0sYEwCQ5YT+7iQXJ/mzMcbX12ZW1a8k+cskL8oi+m9bt96Hxxh7l/D6AMAmtv3W/Rjj5jHGn+4f+Wn+A0nePN09f7uvAwAcvmUc0R/IP07TxzdY9l1V9bIkT0ny+SQfGGPcdYTHAwAr5YiFvqr2JPnp6e47N3jID0+3/dd5b5Irxhj3HalxAcAqOZJH9K9L8swkN40x3rXf/MeS/EYWJ+LdO807LcneJBckeU9VnTHG+NLBXqCq7txk0albHTQAdFLffDL8Ep606uVJ3pDk40nOHWM8dAjr7EnyviTPTnLVGOMNh7DOgUL/xEMfMQDsSh8aY5y1nSdY+hF9Vf1CFpH/6yQXHUrkk2SM8XhVvSWL0J83PcfB1tnwHz/9AnDmIQ8aAJpa6pXxquqqJG/M4rPwF0xn3h+Oz03T45Y5LgBYVUsLfVX9cpLXJ/lwFpH/7Bae5uxpeu8BHwUAHJKlhL6qXpPFyXd3ZvF2/YMHeOyZ6y+LO82/KMkrprtvXca4AGDVbftv9FV1RZJfT/K1JLcneXlVrX/YvjHGddPPv5XkGVV1R5LPTPNOS3Lh9PNrxhh3bHdcAMByTsZ76jQ9JslVmzzm1iTXTT9fn+TSJD+Q5AVJvjXJ3yf54yRvGmPcvoQxAQA5Qh+vm5uz7gFoYtsfr/N99ADQmNADQGNCDwCNCT0ANCb0ANCY0ANAY0IPAI0JPQA0JvQA0JjQA0BjQg8AjQk9ADQm9ADQmNADQGNCDwCNCT0ANCb0ANCY0ANAY0IPAI0JPQA0JvQA0JjQA0BjQg8AjQk9ADQm9ADQmNADQGNCDwCNCT0ANCb0ANCY0ANAY11Df9LcAwCAJThpu0+wZwmD2I0enab7Nll+6jT9+JEfShu22dbYbltjux0+22xrdvN2Oynf6NmW1Rhj+0M5ylTVnUkyxjhr7rEcLWyzrbHdtsZ2O3y22daswnbr+tY9ABChB4DWhB4AGhN6AGhM6AGgsZU86x4AVoUjegBoTOgBoDGhB4DGhB4AGhN6AGhM6AGgMaEHgMZWKvRV9d1V9QdV9XdV9dWq2ldVV1fVCXOPbbeattHY5PbA3OObS1VdVlVvrKrbq+rRaXu89SDrnFNVN1XVQ1X15aq6q6quqqpjdmrcczuc7VZVJx1g3xtVdcNOj38OVfWUqnppVb29qu6Z9p1Hqup9VXVlVW343/FV398Od7t13t+6fh/9N6mqpye5I8l3JPmTLL57+AeT/GKS51fVuWOMz884xN3skSRXbzD/izs9kF3k1UlOz2IbfCbf+E7rDVXVjyd5W5KvJPmjJA8l+bEkr09ybpLLj+Rgd5HD2m6TjyR5xwbzP7rEce1mlye5Nsn9SW5Jcl+S70zywiRvSfKCqrp87Hf1M/tbki1st0m//W2MsRK3JO9KMpL8x3Xzf2ua/+a5x7gbb0n2Jdk39zh22y3JBUmekaSSnD/tQ2/d5LFPSvLZJF9N8qz95h+bxS+fI8mL5/437cLtdtK0/Lq5xz3zNrswi0h/y7r5J2YRr5HkRfvNt79tbbu13d9W4q376Wj+eVlE67+vW/xfknwpyU9V1XE7PDSOUmOMW8YYnxzTfyEO4rIk357khjHGB/d7jq9kcYSbJD93BIa56xzmdiPJGOPmMcafjjG+vm7+A0nePN09f79F9rdsabu1tSpv3V8wTd+9wf/oX6iq92fxi8DZSd6z04M7Cjyhqn4yyfdk8UvRXUluG2N8bd5hHTUunKbv3GDZbUkeS3JOVT1hjPHVnRvWUeO7quplSZ6S5PNJPjDGuGvmMe0W/zhNH99vnv3t4Dbabmva7W+rEvpTpundmyz/ZBahPzlCv5ETk1y/bt6nquolY4xb5xjQUWbT/W+M8XhVfSrJ9yV5WpKP7eTAjhI/PN3+SVW9N8kVY4z7ZhnRLlBVe5L89HR3/6jb3w7gANttTbv9bSXeuk9y/DR9ZJPla/OfvANjOdr8YZKLsoj9cUm+P8nvZPH3rD+vqtPnG9pRw/63NY8l+Y0kZyU5Ybo9N4sTq85P8p4V/3Pb65I8M8lNY4x37Tff/nZgm223tvvbqoSeLRpjvHb6W9ffjzEeG2N8dIzxs1mcxPgvkuydd4R0Ncb47Bjj18YYHxpjPDzdbsvi3bf/neRfJ3npvKOcR1W9PMkrs/j00E/NPJyjxoG2W+f9bVVCv/Yb7PGbLF+b//AOjKWLtZNZzpt1FEcH+98SjTEez+LjUckK7n9V9QtJ3pDkr5NcMMZ4aN1D7G8bOITttqEO+9uqhP4T0/TkTZY/Y5pu9jd8vtnnpulR+VbWDtt0/5v+XvjULE4KuncnB3WUW8n9r6quSvLGLD7TfcF0Bvl69rd1DnG7HchRvb+tSuhvmabP2+BqSN+WxQUkHkvyFzs9sKPY2dN0Zf5jsQ03T9Pnb7DsvCRPTHLHCp8BvRUrt/9V1S9nccGbD2cRq89u8lD7234OY7sdyFG9v61E6McYf5Pk3VmcQPbz6xa/Novf0q4fY3xph4e2q1XV92508klVnZTkTdPdA172lSTJjUkeTPLiqnrW2syqOjbJb053r51jYLtZVZ250eVdq+qiJK+Y7q7E/ldVr8niJLI7k1w0xnjwAA+3v00OZ7t13t9qVa5bscElcD+W5NlZfMb+7iTnDJfA/Weqam8WJ67cluTTSb6Q5OlJfjSLq2zdlOTSMcY/zDXGuVTVJUkume6emOTfZvHb/u3TvAfHGK9a9/gbs7gk6Q1ZXJL04iw+CnVjkn+3CheROZztNn2k6RlZ/P/2M9Py0/KNz4m/ZoyxFq62quqKJNcl+VoWbz9vdDb9vjHGdfuts/L72+Fut9b729yX5tvJW5J/lcXHxe5P8g9ZxOvqJCfMPbbdeMvioyX/I4szVB/O4iITn0vyv7L4HGrNPcYZt83eLC6Xudlt3wbrnJvFL0f/L8mXk/yfLI4Ujpn737Mbt1uSK5P8zyyuaPnFLC7pel8W125/ztz/ll20zUaS99rftrfdOu9vK3NEDwCraCX+Rg8Aq0roAaAxoQeAxoQeABoTegBoTOgBoDGhB4DGhB4AGhN6AGhM6AGgMaEHgMaEHgAaE3oAaEzoAaAxoQeAxoQeABoTegBo7P8Dyg7+qOeMN8MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot an example\n",
    "plt.imshow(images[3].numpy().squeeze(), cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Flatten the batch of images images. Then build a multi-layer network with 784 input units, 256 hidden units, and 10 output units using random tensors for the weights and biases. For now, use a sigmoid activation for the hidden layer. Leave the output layer without an activation, we'll add one that gives us a probability distribution next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "#use activation func defined above\n",
    "\n",
    "inputs = images.view(images.shape[0], -1)\n",
    "#batch size remains the same while -1 flattens the image\n",
    "\n",
    "W1 = torch.randn(784,256)\n",
    "B1 = torch.randn(256)\n",
    "\n",
    "W2=torch.randn(256,10)\n",
    "B2=torch.randn(10)\n",
    "\n",
    "h = activation(torch.mm(inputs,W1)+B1)\n",
    "output = activation(torch.mm(h,W2)+B2)\n",
    "\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
